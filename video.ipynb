{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from darknet import Darknet\n",
    "\n",
    "# Set the location and name of the cfg file\n",
    "cfg_file = './cfg/yolov3.cfg'\n",
    "\n",
    "# Set the location and name of the pre-trained weights file\n",
    "weight_file = './weights/yolov3.weights'\n",
    "\n",
    "# Set the location and name of the COCO object classes file\n",
    "namesfile = 'data/coco.names'\n",
    "\n",
    "# Load the network architecture\n",
    "m = Darknet(cfg_file)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "m.load_weights(weight_file)\n",
    "\n",
    "# Load the COCO object classes\n",
    "class_names = load_class_names(namesfile)\n",
    "\n",
    "# Set the NMS threshold\n",
    "nms_thresh = 0.6\n",
    "\n",
    "# Set the IOU threshold\n",
    "iou_thresh = 0.4\n",
    "\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA) # because Bokeh expects a RGBA image\n",
    "frame=cv2.flip(frame, -1) # because Bokeh flips vertically\n",
    "width=frame.shape[1]\n",
    "height=frame.shape[0]\n",
    "p = figure(x_range=(0,width), y_range=(0,height), output_backend=\"webgl\", width=width, height=height)\n",
    "myImage = p.image_rgba(image=[frame], x=0, y=0, dw=width, dh=height)\n",
    "show(p, notebook_handle=True)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the image to RGB\n",
    "    original_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # We resize the image to the input width and height of the first layer of the network.    \n",
    "    resized_image = cv2.resize(original_image, (m.width, m.height))\n",
    "\n",
    "    # Set the IOU threshold. Default value is 0.4\n",
    "    iou_thresh = 0.4\n",
    "\n",
    "    # Set the NMS threshold. Default value is 0.6\n",
    "    nms_thresh = 0.6\n",
    "\n",
    "    # Detect objects in the image\n",
    "    boxes = detect_objects(m, resized_image, iou_thresh, nms_thresh)\n",
    "\n",
    "    # Print the objects found and the confidence level\n",
    "#     print_objects(boxes, class_names)\n",
    "\n",
    "    #Plot the image with bounding boxes and corresponding object class labels\n",
    "    frame = plot_boxes(original_image, boxes, class_names, plot_labels = True)\n",
    "    \n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_RGB2RGBA)\n",
    "    frame=cv2.flip(frame, 0)\n",
    "    myImage.data_source.data['image']=[frame]\n",
    "    push_notebook()\n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
